{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "import pandas as pd\n",
    "# Set the maximum number of rows and columns to display\n",
    "pd.set_option('display.max_rows', 200)  # Adjust this number as needed\n",
    "pd.set_option('display.max_columns', 50)  # Adjust this number as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Get shapefiles\n",
    "import geopandas as gpd\n",
    "poly = gpd.GeoDataFrame.from_file('../../data_CityEvent/Shp/US_blck_grp_2019.shp')\n",
    "poly = poly.to_crs(epsg=4326)\n",
    "california = poly[poly['STATEFP']=='06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "from shapely.geometry import shape\n",
    "\n",
    "def parse_geometry(geo):\n",
    "    \"\"\"Parse the GEO field into a Shapely geometry (Point, Polygon, or MultiPolygon).\"\"\"\n",
    "    if pd.isna(geo):\n",
    "        return None\n",
    "    try:\n",
    "        # Convert the GEO string into a Python dict\n",
    "        geo_json = json.loads(geo)\n",
    "\n",
    "        # Use shapely's shape() to parse the geometry\n",
    "        geometry = shape(geo_json)\n",
    "\n",
    "        # Ensure the parsed geometry is one of the expected types\n",
    "        if geometry.geom_type in {\"Point\", \"Polygon\", \"MultiPolygon\"}:\n",
    "            return geometry\n",
    "        else:\n",
    "            print(f\"Unsupported geometry type: {geometry.geom_type}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing geometry: {e}\")\n",
    "        return None\n",
    "\n",
    "def assign_cbgid(df, shapefile):\n",
    "    df['geometry'] = df['GEO'].apply(parse_geometry)\n",
    "    df = df.dropna(subset=['geometry'])\n",
    "    df = gpd.GeoDataFrame(df, geometry='geometry', crs='EPSG:4326')\n",
    "    shapefile = gpd.GeoDataFrame(shapefile, geometry='geometry', crs=\"EPSG:4326\")\n",
    "    shapefile = shapefile[['GEOID', 'geometry']]\n",
    "\n",
    "    assigned_df = gpd.sjoin(df, shapefile, how='inner', predicate='intersects')\n",
    "    print(df.shape)\n",
    "    print(assigned_df.shape)\n",
    "    assigned_df = assigned_df.drop(columns=['index_right'])\n",
    "    print(assigned_df.shape)\n",
    "    return(assigned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_attended = pd.read_csv('../../data_CityEvent/Cityevents/Demand_Intelligence_for_Attended_Events_California-0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save function\n",
    "def save_df_by_event_category(df):\n",
    "    columns = [col for col in df.columns]\n",
    "    categories = list(df['CATEGORY'].unique())\n",
    "    for category in categories:\n",
    "        df_by_category = df[df['CATEGORY'] == category]\n",
    "        print(f'{category} shape: {df_by_category.shape}')\n",
    "        df_by_category.to_csv(f'../../data_CityEvent/processed/1.4_updated_events_cbgid_assigned_by_category/attended_{category}.csv', index=False)  # Set index=False to avoid saving the index\n",
    "    \n",
    "    print('Successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from utils.time.time_converted_to_boston import convert_time_of_dataframe\n",
    "\n",
    "\n",
    "df_attended = df_attended[(df_attended['CANCELLED_DT'].isna()) & (df_attended['POSTPONED_DT'].isna())]\n",
    "\n",
    "df_attended = df_attended.drop(['CANCELLED_DT', 'POSTPONED_DT'], axis=1)\n",
    "\n",
    "datetime_columns = ['CREATE_DT', 'UPDATE_DT', 'EVENT_START', 'EVENT_END', 'PREDICTED_END', 'ROW_INSERTED_DT', 'ROW_UPDATED_DT']\n",
    "df_attended[datetime_columns] = df_attended[datetime_columns].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "df_attended_converted = convert_time_of_dataframe(df_attended)\n",
    "\n",
    "df_attended_cbgid = assign_cbgid(df_attended_converted, california)\n",
    "\n",
    "df_attended_cbgid.to_csv(f'../../data_CityEvent/processed/1.4_updated_events_cbgid_assigned/df_attended.csv', index=False)\n",
    "\n",
    "save_df_by_event_category(df_attended_cbgid)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
